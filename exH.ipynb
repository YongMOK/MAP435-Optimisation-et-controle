{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP 435 - TP à trous à rendre pour le dimanche 12 mai 23h59\n",
    "\n",
    "Le but de cet exercice est de compléter les fonctions manquantes en remplaçant les parties `# YOUR CODE HERE` par votre code.\n",
    "\n",
    "**Attention** la correction des notebooks se faisant de manière automatique :\n",
    "- il faut que vous supprimiez la ligne `raise NotImplementedError()` ;\n",
    "- les seules cellules que vous devez modifier sont celles comportant la mention `# YOUR CODE HERE` ;\n",
    "- **vous ne devez pas modifier le nom du fichier faute de quoi votre devoir ne sera pas corrigé**.\n",
    "\n",
    "Merci d'inscrire votre nom dans la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOM = \"MOK Yong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cba23b507fc37ad1d11a6892a2cfae4",
     "grade": false,
     "grade_id": "cell-a3abfd1002650dce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Amélioration des méthodes de gradient\n",
    "\n",
    "Le but de cet exercice est d'améliorer la convergence de l'algorithme du gradient à pas optimal classique décrit dans votre polycopié par une méthode que l'on explicitera plus loin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffe98b2b3c7733c522a6e1ad04bb3b23",
     "grade": false,
     "grade_id": "cell-299a149d172aeaee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Chargement des librairies utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25c0d1cc239810ca284a63f878b063dc",
     "grade": false,
     "grade_id": "cell-35eac054973937f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.testing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "from scipy.sparse import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c3136cf35155e2bbe3b771ff5bdedd4",
     "grade": false,
     "grade_id": "cell-99cd2db2769a3672",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Algorithmes \n",
    "\n",
    "### Algorithme du gradient pas optimal\n",
    "\n",
    "Vous trouverez ci-dessous l'algorithme du gradient à pas optimal. Cet algorithme est complet et **vous n'avez pas à le modifier**. Il est simplement présent afin de comparer le résultat que vous obtiendrez avec l'algorithme du gradient à pas optimal préconditionné.\n",
    "\n",
    "On construit la suite $x_k$ définie par :\n",
    "\n",
    "\\begin{equation}\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "&x_0 \\in \\mathbb R^N \\text{ quelconque} \\\\\n",
    "&x_{k+1} = x_k - \\mu_k \\nabla J(x_k),\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "\n",
    "où le pas de descente $\\mu_k$ est choisi tel que :\n",
    "\n",
    "$$ J(x_{k+1})=\\min_{\\mu \\in \\mathbb R} J(x_k-\\mu\\nabla J(x_k)).$$\n",
    "\n",
    "Lorsqu'on travaille avec une fonctionnelle quadratique  $J: \\mathbb R^N \\rightarrow \\mathbb R$ telle que  \n",
    "$$ J(x) = \\frac12 \\langle Ax,x\\rangle - \\langle b,x\\rangle,$$\n",
    "avec $A$ une matrice symétrique définie positive, on sait que le pas de descente optimal est donné par \n",
    "$$\\mu_k=\\frac{\\|r_k\\|^2}{\\left\\langle r_k,Ar_k\\right\\rangle} \\text{ avec } r_k= Ax_k-b=\\nabla J(x_k).$$\n",
    "\n",
    "Par souci de simplicité on donne seulement ici l'algorithme du gradient à pas optimal dans le cas d'une fonctionnelle quadratique. Ainsi les arguments sont : la fonctionnelle à minimiser `f`, la matrice $A=$ `mat_A`, le vecteur $b=$ `vec_b` et un point initial `x_init`. \n",
    "On y ajoute les arguments optionnels suivants : la tolérance demandée `tol` et le nombre maximal d'itérations `maxiter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97eae402a074838aed1a1418a66f56c6",
     "grade": false,
     "grade_id": "cell-3f8a29d7c2946ba2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradientPasOpt(f,mat_A,vec_b,x_init,tol=1e-06,maxiter=200):\n",
    "    \n",
    "    # initialisation\n",
    "    x=x_init.copy()\n",
    "    xtab=[]\n",
    "    ftab=[]\n",
    "    \n",
    "    xtab.append(x) # on ajoute x à la liste xtab\n",
    "    ftab.append(f(x))\n",
    "    \n",
    "    it=0 # compteur d'itération\n",
    "    \n",
    "    while((it==0) or (it<maxiter and np.linalg.norm(mat_A@xtab[-1]-vec_b)>tol)): \n",
    "        \n",
    "        r=mat_A@x-vec_b\n",
    "        pas = np.dot(r,r)/np.dot(r,mat_A@r)\n",
    " \n",
    "        x=x-pas*r\n",
    "        \n",
    "        xtab.append(x)\n",
    "        ftab.append(f(x))\n",
    "        \n",
    "        it=it+1\n",
    "    \n",
    "    # booléen pour indiquer la convergence\n",
    "    if(it==maxiter):\n",
    "        conv = False\n",
    "    else:\n",
    "        conv = True\n",
    "    \n",
    "    return xtab, ftab, conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e46680d9f04bd8424a6283920098711d",
     "grade": false,
     "grade_id": "cell-631e2bbee37698b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Gradient à pas optimal préconditionné\n",
    "\n",
    "On souhaite maintenant améliorer la vitesse de convergence de cet algorithme. Pour cela on va utiliser un préconditionnement. \n",
    "Dans ce cas là, si $P$ est la matrice de préconditionnement, l'algorithme de gradient à pas optimal devient :\n",
    "$$x_{k+1} = x_k-\\mu_k P^{-1} \\nabla J(x_k).$$\n",
    "\n",
    "\n",
    "On vient de voir que dans le cas d'une fonctionnelle quadratique $ J(x) = \\frac12 \\langle Ax,x\\rangle - \\langle b,x\\rangle$ avec $A$ symétrique définie positive, le pas de descente optimal dans l'algorithme du gradient à pas optimal (sans préconditionnement) est donné par :\n",
    "$$\\mu_k=\\frac{\\|r_k\\|^2}{\\left\\langle r_k,Ar_k\\right\\rangle} \\text{ avec } r_k= Ax_k-b.$$\n",
    "\n",
    "On rappelle également que ce pas optimal a été obtenu en minimisant la fonction $\\rho \\mapsto J(x_k-\\rho\\nabla J(x_k))$.\n",
    "\n",
    "**Q1)** Après avoir calculé (à la main) la nouvelle valeur du pas optimal dans le cas du gradient à pas optimal préconditionné (pour le cas d'une fonctionnelle quadratique), complétez  le code ci-dessous qui permet de calculer le pas optimal  en fonction du résidu $r_k=\\nabla J(x_k) = Ax_k-b=$ `r`, de la matrice du problème $A=$ `mat_A` et de la matrice $C=P^{-1}=$ `mat_C`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1691f60117c185a2255d60bb98647ef8",
     "grade": false,
     "grade_id": "cell-4d2edc1dac7d15d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calcul_pas_precond(r, mat_A, mat_C):\n",
    "    # Preconditioned residual\n",
    "    Cr = mat_C@r\n",
    "    \n",
    "    # Applying A to the preconditioned residual\n",
    "    A_Cr = mat_A@Cr\n",
    "    \n",
    "    # Calculating the optimal step size mu_k\n",
    "    mu_k = np.dot(r, Cr) / np.dot(Cr, A_Cr)\n",
    "    \n",
    "    return mu_k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2)** Complétez  le code ci-dessous qui permet de calculer l'itérée $x_{k+1}$ en fonction de l'itérée $x_k$ pour l'algorithme du gradient à pas optimal préconditionné.\n",
    "\n",
    "Les arguments de cette fonction sont : la valeur de l'itérée $x_k$ notée `x`, le gradient de la fonctionnelle à minimiser qui est égal au résidu `r`, la matrice de préconditionnement `mat_C` ainsi que le pas `pas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d92fc1e3dd1de81f79991cb00cdd955",
     "grade": false,
     "grade_id": "cell-6a7124dde6882dcf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calcul_xplus(x, r, mat_C, pas):\n",
    "    x = x.copy()\n",
    "    # Calculate C times r\n",
    "    Cr = mat_C@r\n",
    "    \n",
    "    # Calculate the update step\n",
    "    update = pas * Cr\n",
    "    \n",
    "    # Update x to get x_k+1\n",
    "    x_k_plus = x - update\n",
    "    \n",
    "    return x_k_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "423e06a6c3d035b8f347e91499988005",
     "grade": false,
     "grade_id": "cell-8cf51bffb9dd3c8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "On donne maintenant l'algorithme du gradient à pas optimal préconditionné dans lequel l'itérée $x_{k+1}$ et le pas optimal sont obtenus en utilisant les fonctions`calcul_xplus` et `calcul_pas_precond` que vous venez de construire.\n",
    "\n",
    "Les arguments de cette fonction sont : la fonctionnelle à minimiser `f`, la matrice $A=$ `mat_A`, le vecteur $b=$ `vec_b`, la matrice `mat_C` et un point initial `x_init`. On y ajoute les arguments optionnels suivants : la tolérance demandée `tol` et le nombre maximal d'itérations `maxiter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "991cae88807f0446ad7cf596dc914e1d",
     "grade": false,
     "grade_id": "cell-c000122a5a730f2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradientPasOpt_precond(f,mat_A,vec_b,mat_C,x_init,tol=1e-06,maxiter=200):\n",
    "    \n",
    "    # initialisation\n",
    "    x=x_init.copy()\n",
    "    xtab=[]\n",
    "    ftab=[]\n",
    "    \n",
    "    xtab.append(x) # on ajoute x à la liste xtab\n",
    "    ftab.append(f(x))\n",
    "    \n",
    "    it=0 # compteur d'itération\n",
    "    \n",
    "    while((it==0) or (it<maxiter and np.linalg.norm(mat_A@xtab[-1]-vec_b)>tol)):\n",
    "           \n",
    "        r = mat_A@x-vec_b\n",
    "        pas = calcul_pas_precond(r, mat_A, mat_C)\n",
    "            \n",
    "        x = calcul_xplus(x, r, mat_C, pas)\n",
    "        \n",
    "        xtab.append(x)\n",
    "        ftab.append(f(x))\n",
    "        \n",
    "        it = it+1\n",
    "    \n",
    "    # booléen pour indiquer la convergence\n",
    "    if(it==maxiter):\n",
    "        conv = False\n",
    "    else:\n",
    "        conv = True\n",
    "    \n",
    "    return xtab, ftab, conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da4f8c380ac2b309c659e38a86417b95",
     "grade": false,
     "grade_id": "cell-f4d7b9a008a9cdde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Définition du problème\n",
    "\n",
    "On va chercher à minimiser la fonctionnelle quadratique suivante $J: \\mathbb R^N \\rightarrow \\mathbb R$ telle que  \n",
    "$$ J(x) = \\frac12 \\langle Ax,x\\rangle - \\langle b,x\\rangle,$$\n",
    "avec $A$ la matrice symmétrique telle que pour $0 \\le i \\le N-1$,\n",
    "$$A_{i,i}=3i^2+8, \\quad A_{i,i+1}=A_{i,i-1}=i+1 \\ \\text{ et } \\ A_{i,i+2}=A_{i,i-2}=-1$$\n",
    "et $b=\\left(i(N-1-i)\\right)_{0 \\le i \\le N-1}$.\n",
    "\n",
    "On rappelle que trouver le minimum de la fonctionnelle $J$ revient alors à résoudre le système linéaire $Ax=b$.\n",
    "\n",
    "\n",
    "**Q3)** Complétez le programme ci-dessous qui pour `N` donné renvoit le vecteur $b$ proposé ci-dessus de taille `N`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98a358b82f7beece8b1a8fa6811e7805",
     "grade": false,
     "grade_id": "cell-3fbd0a5126b4bd7b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fct_vecb(N):\n",
    "    # YOUR CODE HERE\n",
    "    b = [(i*(N-1-i)) for i in range(N)]\n",
    "    return np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "629f2aa215c9f20845d4074f12b37057",
     "grade": true,
     "grade_id": "cell-b45f3b49eef311c4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  19  36  51  64  75  84  91  96  99 100  99  96  91  84  75  64  51\n",
      "  36  19   0]\n"
     ]
    }
   ],
   "source": [
    "# on affiche le vecteur que vous avez construit.\n",
    "print(fct_vecb(21))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4)** Complétez le programme ci-dessous qui pour `N` donné renvoit la matrice carrée de taille `N` **creuse** $A$ décrite ci-dessus. \n",
    "**Faites attention à bien construire une matrice creuse.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cef98bedc9194f109e632ca466fd6a6",
     "grade": false,
     "grade_id": "cell-6b9fb2709ee4391b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fct_matA(N):\n",
    "    # YOUR CODE HERE\n",
    "    A_diag = [(3 * i**2 + 8) for i in range(N)]\n",
    "    off_diag1 = [(i + 1) for i in range(0, N)]\n",
    "    off_diag2 = [-1 for i in range(2, N)]\n",
    "    A = sparse.diags(\n",
    "        [off_diag2, off_diag1, A_diag, off_diag1, off_diag2],\n",
    "        offsets=[-2, -1, 0, 1, 2],\n",
    "        shape=(N, N),\n",
    "        format='csr'  # Compressed Sparse Row format\n",
    "    )\n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87c97f0936cee1394203deb9e51dd513",
     "grade": true,
     "grade_id": "cell-34483fdba036ec9d",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.   1.  -1.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  1.  11.   2.  -1.   0.   0.   0.   0.   0.   0.]\n",
      " [ -1.   2.  20.   3.  -1.   0.   0.   0.   0.   0.]\n",
      " [  0.  -1.   3.  35.   4.  -1.   0.   0.   0.   0.]\n",
      " [  0.   0.  -1.   4.  56.   5.  -1.   0.   0.   0.]\n",
      " [  0.   0.   0.  -1.   5.  83.   6.  -1.   0.   0.]\n",
      " [  0.   0.   0.   0.  -1.   6. 116.   7.  -1.   0.]\n",
      " [  0.   0.   0.   0.   0.  -1.   7. 155.   8.  -1.]\n",
      " [  0.   0.   0.   0.   0.   0.  -1.   8. 200.   9.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  -1.   9. 251.]]\n"
     ]
    }
   ],
   "source": [
    "# on affiche la matrice que vous avez construite\n",
    "print(fct_matA(10).todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit ici d'utiliser un préconditionnement SOR (Successive Over-Relaxation), c'est à dire que la matrice de précondionnement est donnée par :\n",
    "$$P=\\omega\\left(D+\\omega L\\right), \\quad \\omega >1,$$\n",
    "où $D,L$ sont des matrices carrées de taille $N$ telle que :\n",
    "- $D$ représente la diagonale de la matrice $A$ ;\n",
    "- $L$ est la partie triangulaire inférieure (sans la diagonale) de la matrice $A$.\n",
    "\n",
    "**Q5)** Complétez la fonction ci-dessous qui pour $\\omega=$ `omega` et `N` donnés renvoit la matrice **creuse** $P$ décrite ci-dessus. \n",
    "**Faites attention à bien construire une matrice creuse.**\n",
    "DEF D et L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a956c105f5f71abef42cb9db03cb6876",
     "grade": false,
     "grade_id": "cell-9473b5600bd800a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fct_matP(N,omega):\n",
    "    # YOUR CODE HERE\n",
    "    A = fct_matA(N)\n",
    "    # Extract D as a diagonal matrix\n",
    "    D = sparse.diags(A.diagonal(), 0, shape=(N, N), format='csr')\n",
    "    \n",
    "    \n",
    "    # Extract L (strictly lower triangular part of A)\n",
    "    L = sparse.tril(A, k=-1)\n",
    "    # Construct the preconditioning matrix P\n",
    "    P = omega * (D + omega * L)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4835344e2d632bbfe413c5021ab4e701",
     "grade": true,
     "grade_id": "cell-5d1b0cd6720bc450",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.6    0.     0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  1.44  13.2    0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [ -1.44   2.88  24.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.    -1.44   4.32  42.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.    -1.44   5.76  67.2    0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.    -1.44   7.2   99.6    0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.    -1.44   8.64 139.2    0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.    -1.44  10.08 186.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.    -1.44  11.52 240.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.    -1.44  12.96 301.2 ]]\n"
     ]
    }
   ],
   "source": [
    "# on affiche la matrice que vous avez construite\n",
    "omega=1.2\n",
    "print(fct_matP(10,omega).todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34ac998ceed82073b840703a612d1720",
     "grade": false,
     "grade_id": "cell-465e17464ba1f40b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Observation des résultats\n",
    "\n",
    "On compare alors l'algorithme du gradient optimal préconditionné au gradient optimal classique.\n",
    "\n",
    "Les résultats obtenus ci-dessous doivent vous permettre de valider ou d'invalider vos codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "723f6b5d229d86e0f25f73e377c76bc4",
     "grade": false,
     "grade_id": "cell-36cde29b9b588351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N=300\n",
    "\n",
    "# Vecteur b\n",
    "vec_b=fct_vecb(N)\n",
    "\n",
    "# Matrice A\n",
    "mat_A=fct_matA(N)\n",
    "\n",
    "\n",
    "# Calcul de la solution\n",
    "sol=linalg.spsolve(mat_A.tocsc(), vec_b, use_umfpack=True)\n",
    "\n",
    "# Fonctionnelle\n",
    "def fct_J(x):\n",
    "    return 0.5*np.dot(x,mat_A@x)-np.dot(vec_b,x)\n",
    "\n",
    "def fct_gradJ(x):\n",
    "    return mat_A@x-b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant construire la matrice utilisée dans l'algorithme de gradient optimal préconditionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_P = fct_matP(N,1.2)\n",
    "mat_C=sp.sparse.csc_matrix(mat_P)\n",
    "mat_C=sp.sparse.linalg.inv(mat_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d8ccb45be15ddc63b9907985ff6b311",
     "grade": false,
     "grade_id": "cell-3bb58f6f6254290d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Algorithme du gradient à pas optimal\n",
      "Erreur =  0.48892525798778164\n",
      "Convergence = False\n",
      "Nombre d itérations =  50000\n",
      "=================================\n",
      "Algorithme du gradient à pas optimal préconditionné\n",
      "Erreur =  3.8346799337732045e-08\n",
      "Convergence = True\n",
      "Nombre d itérations =  8\n"
     ]
    }
   ],
   "source": [
    "x_init=np.ones(N)\n",
    "\n",
    "print('=================================')\n",
    "print('Algorithme du gradient à pas optimal')\n",
    "x_PasOpt_sansprecond, f_PasOpt, conv_PasOpt = gradientPasOpt(fct_J,mat_A,vec_b,x_init,1e-6,50000)\n",
    "print('Erreur = ',np.linalg.norm(sol-x_PasOpt_sansprecond[-1]))\n",
    "print('Convergence =',conv_PasOpt)\n",
    "print('Nombre d itérations = ',np.shape(x_PasOpt_sansprecond)[0]-1)\n",
    "\n",
    "\n",
    "print('=================================')\n",
    "print('Algorithme du gradient à pas optimal préconditionné')\n",
    "x_PasOpt_precond, f_PasOpt, conv_PasOpt = gradientPasOpt_precond(fct_J,mat_A,vec_b,mat_C,x_init,1e-6,5000)\n",
    "print('Erreur = ',np.linalg.norm(sol-x_PasOpt_precond[-1]))\n",
    "print('Convergence =',conv_PasOpt)\n",
    "print('Nombre d itérations = ',np.shape(x_PasOpt_precond)[0]-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
